{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8edf9c-fa3e-40ff-8eeb-2d8ce324f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import LeakyReLU, Reshape, BatchNormalization, Conv2DTranspose, Conv2D,UpSampling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d463f66-1790-4e10-8341-e4d5f4b72763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_CACHE_PATH'] = 'D:/cuda_cache'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf1d03f-e281-4fb2-8c49-3fe412bc3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(5,5),\n",
    "    strides=(1,1),\n",
    "    up_size=(2,2),\n",
    "    padding='same',\n",
    "    use_bn=True,\n",
    "    use_bias=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3\n",
    "):\n",
    "    x = UpSampling2D(up_size)(x)\n",
    "    x = Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = Dropout(drop_value)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47957052-bc2f-489c-b3f1-22ca36d2c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_model(\n",
    "    z_dim = 128, \n",
    "    n_filter = 64\n",
    "):\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Dense 2*2*n_filter*8\n",
    "    x = Dense(2*2*n_filter*8, use_bias=True)(z_input)\n",
    "\n",
    "    # 2*2*512\n",
    "    x = Reshape((2,2,n_filter*8))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # 4*4*256\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=4*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    \n",
    "\n",
    "    # 8*8*128\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=2*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "\n",
    "    # 16*16*64\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    # 32*32*3\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=3,\n",
    "        activation=Activation('tanh'),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    \n",
    "    g_model = Model(z_input, x, name=\"generator\")\n",
    "\n",
    "    return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e925e3-2a78-42e5-b080-7207ee9915c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              264192    \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2, 2, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 4, 4, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 256)         3277056   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         819328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        204864    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 3)         4803      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,574,095\n",
      "Trainable params: 4,572,169\n",
      "Non-trainable params: 1,926\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_model = build_generator_model()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b525157b-5c9a-40b7-96f0-ee64606193e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3,3),\n",
    "    strides=(1,1),\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5\n",
    "):\n",
    "    x = Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "\n",
    "    if use_dropout:\n",
    "        x = Dropout(drop_value)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "582d6b5e-0acd-4c4b-9170-718fbbbf3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_model( \n",
    "    input_shape=(32,32,3), \n",
    "    n_filter=64\n",
    "):\n",
    "    input = Input(shape=input_shape)\n",
    "    \n",
    "    # 16*16*64\n",
    "    x = con_block(\n",
    "        input,\n",
    "        filters=n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "\n",
    "    # 8*8*128\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=2*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    # 4*4*256\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=4*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    # 2*2*512\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=8*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    d_model = Model(input, x, name=\"discriminator\")\n",
    "    return d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc90f19e-efda-442a-a275-2fefc2a901e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 64)        4864      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 8, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 2, 2, 512)         3277312   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,312,449\n",
      "Trainable params: 4,310,529\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_model = build_discriminator_model()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61314d6-4dcb-48ae-849b-a215103c79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANs(Model):\n",
    "    def __init__():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7afa8a04-e226-405e-8249-45c4080d0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name):\n",
    "    (X_train, _), (_, _) = cifar10.load_data()\n",
    "    # Chuyển hình ảnh từ (0 -> 255) về ( -1 -> 1) \n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_train = 2*(X_train/255)-1\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6b8b5a-85a8-47da-932e-8027601524c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Hàm vẽ loss function\n",
    "def plot_loss(losses):\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761b4498-69c8-42d7-b66d-5fd2f1573007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, filename):\n",
    "    h, w, c = images.shape[1:]\n",
    "    grid_size = ceil(np.sqrt(images.shape[0]))\n",
    "    images = (images + 1) / 2. * 255.\n",
    "    images = images.astype(np.uint8)\n",
    "    images = (images.reshape(grid_size, grid_size, h, w, c)\n",
    "    \n",
    "    .transpose(0, 2, 1, 3, 4)\n",
    "    .reshape(grid_size*h, grid_size*w, c))\n",
    "    \n",
    "    #plt.figure(figsize=(16, 16))\n",
    "    plt.imsave(filename, images)\n",
    "    plt.imshow(images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a61d9-c014-41f0-9a91-4a8b55e036bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_name=cifar10,\n",
    "          epochs=200,\n",
    "          plt_frq=10,\n",
    "          BATCH_SIZE=128,\n",
    "          z_dim = 100,\n",
    "          n_filter=64,\n",
    "          lr_d=5e-5,\n",
    "          lr_gan=5e-5):\n",
    "    \n",
    "    X_train = get_data(data_name)\n",
    "    opt_discriminator = RMSprop(lr=lr_d)\n",
    "    opt_gan = RMSprop(lr=lr_gan)\n",
    "    \n",
    "    g = build_generator(z_dim, n_filter)\n",
    "    d = build_discriminator(input_shape=(32,32,3), n_filter=n_filter)\n",
    "    d.compile(loss='binary_crossentropy', optimizer=opt_discriminator, metrics=['accuracy'])\n",
    "\n",
    "    # Mô hình tổng hợp dùng để huấn luyện bộ sinh generator\n",
    "    d.trainable = False\n",
    "    inputs = Input(shape=(z_dim,))\n",
    "    hiden = g(inputs)\n",
    "    outputs = d(hiden)\n",
    "    \n",
    "    gan = Model(inputs, outputs)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=opt_gan, metrics=['accuracy'])\n",
    "    \n",
    "    losses = {\"D\": [], \"G\": []}\n",
    "    HALF_BATCH_SIZE = BATCH_SIZE // 2\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print(f'Epochs: {epochs}')\n",
    "    print(f'Batch size: {BATCH_SIZE}')\n",
    "    print(f'Batches per epoch: {batchCount}')\n",
    "\n",
    "    noise_fixed = np.random.uniform(-1, 1, size=(36, z_dim))\n",
    "\n",
    "    for e in tqdm(range(1, epochs+1)):\n",
    "        for _ in range(batchCount):\n",
    "            \n",
    "            if e <= 5:\n",
    "                img_real = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "                noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, z_dim))\n",
    "                img_fake = g.predict(noise)\n",
    "                y_real = np.ones(shape=(BATCH_SIZE, 1))\n",
    "                y_fake = np.zeros(shape=(BATCH_SIZE, 1))\n",
    "                d.trainable = True\n",
    "                d_loss_real = d.train_on_batch(img_real, y_real)\n",
    "                d_loss_fake = d.train_on_batch(img_fake, y_fake)\n",
    "                d_loss_function = (d_loss_real[0] + d_loss_fake[0])\n",
    "                d_loss_accuracy = (d_loss_real[1] + d_loss_fake[1]) / 2\n",
    "                d_loss = [d_loss_function, d_loss_accuracy]\n",
    "                \n",
    "            elif e > 5:\n",
    "                img_real = X_train[np.random.randint(0, X_train.shape[0], size=HALF_BATCH_SIZE)]\n",
    "                noise = np.random.uniform(-1, 1, size=(HALF_BATCH_SIZE, z_dim))\n",
    "                img_fake = g.predict(noise)\n",
    "                y_real = np.ones(shape=(HALF_BATCH_SIZE, 1))\n",
    "                y_fake = np.zeros(shape=(HALF_BATCH_SIZE, 1))\n",
    "                d.trainable = True\n",
    "                d_loss_real = d.train_on_batch(img_real, y_real)\n",
    "                d_loss_fake = d.train_on_batch(img_fake, y_fake)\n",
    "                d_loss_function = (d_loss_real[0] + d_loss_fake[0])\n",
    "                d_loss_accuracy = (d_loss_real[1] + d_loss_fake[1]) / 2\n",
    "                d_loss = [d_loss_function, d_loss_accuracy]\n",
    "\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, z_dim))\n",
    "            y_real_g = np.ones(shape=(BATCH_SIZE, 1))\n",
    "            d.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y_real_g)\n",
    "        \n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        if e == 1 or e%plt_frq == 0:\n",
    "            print('Epoch {}'.format(e))\n",
    "            fake_images = g.predict(noise_fixed)\n",
    "            plot_images(fake_images, \"img/fake_images_e_{}.png\".format(e))\n",
    "\n",
    "    #plot_loss(losses)\n",
    "    \n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b26407-c9c3-43cf-b0b2-4e7baff9b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xoa bo dem\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c6a585-a874-4e24-8b39-66cc0781db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_data(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad42eb34-9212-4fda-84c7-96da75fd4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81151019-1355-40a4-9487-8c7683daa6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
