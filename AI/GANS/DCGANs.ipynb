{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8edf9c-fa3e-40ff-8eeb-2d8ce324f98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape, BatchNormalization, Conv2DTranspose, Conv2D,UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import keras\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import os\n",
    "os.environ['CUDA_CACHE_PATH'] = 'D:/cuda_cache'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Tắt tất cả các thông báo log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf1d03f-e281-4fb2-8c49-3fe412bc3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(5,5),\n",
    "    strides=(1,1),\n",
    "    up_size=(2,2),\n",
    "    padding='same',\n",
    "    use_bn=True,\n",
    "    use_bias=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3\n",
    "):\n",
    "    x = UpSampling2D(up_size)(x)\n",
    "    x = Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = Dropout(drop_value)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47957052-bc2f-489c-b3f1-22ca36d2c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_model(\n",
    "    z_dim = 128, \n",
    "    n_filter = 64\n",
    "):\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Dense 2*2*n_filter*8\n",
    "    x = Dense(2*2*n_filter*8, use_bias=True)(z_input)\n",
    "\n",
    "    # 2*2*512\n",
    "    x = Reshape((2,2,n_filter*8))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # 4*4*256\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=4*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    \n",
    "\n",
    "    # 8*8*128\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=2*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "\n",
    "    # 16*16*64\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    # 32*32*3\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        filters=3,\n",
    "        activation=Activation('tanh'),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        up_size=(2,2),\n",
    "        padding='same',\n",
    "        use_bn=True,\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3\n",
    "    )\n",
    "    \n",
    "    g_model = Model(z_input, x, name=\"generator\")\n",
    "\n",
    "    return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b525157b-5c9a-40b7-96f0-ee64606193e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3,3),\n",
    "    strides=(1,1),\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5\n",
    "):\n",
    "    x = Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "\n",
    "    if use_dropout:\n",
    "        x = Dropout(drop_value)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582d6b5e-0acd-4c4b-9170-718fbbbf3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_model( \n",
    "    input_shape=(32,32,3), \n",
    "    n_filter=64\n",
    "):\n",
    "    input = Input(shape=input_shape)\n",
    "    \n",
    "    # 16*16*64\n",
    "    x = con_block(\n",
    "        input,\n",
    "        filters=n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "\n",
    "    # 8*8*128\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=2*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    # 4*4*256\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=4*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    # 2*2*512\n",
    "    x = con_block(\n",
    "        x,\n",
    "        filters=8*n_filter,\n",
    "        activation=LeakyReLU(0.2),\n",
    "        kernel_size=(5,5),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        use_bias=True,\n",
    "        use_bn=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.5\n",
    "    )\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    d_model = Model(input, x, name=\"discriminator\")\n",
    "    return d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e61314d6-4dcb-48ae-849b-a215103c79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANs(Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        generator,\n",
    "        discriminator,\n",
    "        latent_dim=128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = tf.random.Generator.from_seed(1337)\n",
    "\n",
    "    def compile(self, optimizer_discriminator, optimizer_generator, loss_d, loss_g):\n",
    "        super().compile()\n",
    "        self.g_optimizer = optimizer_generator\n",
    "        self.d_optimizer = optimizer_discriminator\n",
    "        self.loss_d = loss_d\n",
    "        self.loss_g = loss_g\n",
    "\n",
    "    def train_step(self, batch_image):\n",
    "        if isinstance(batch_image, tuple):\n",
    "            batch_image = batch_image[0]\n",
    "\n",
    "        batch_size = tf.shape(batch_image)[0]\n",
    "        # Tạo vector latent\n",
    "        random_latent_vectors = self.seed_generator.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        # Tạo ảnh giả \n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        # Gán nhãn giả là 0 và nhãn thật là 1\n",
    "        y_fake = tf.zeros((batch_size, 1)) + 0.05 * tf.random.uniform(tf.shape(tf.zeros((batch_size, 1))))\n",
    "        y_real = tf.ones((batch_size, 1)) + 0.05 * tf.random.uniform(tf.shape(tf.ones((batch_size, 1))))\n",
    "\n",
    "        # Huấn luyện Discriminator với ảnh thật\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred_real = self.discriminator(batch_image, training=True)\n",
    "            d_loss_r = self.loss_d(y_real, y_pred_real)\n",
    "        \n",
    "        d_gradient_real = tape.gradient(d_loss_r, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradient_real, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Huấn luyện Discriminator với ảnh giả\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred_fake = self.discriminator(generated_images, training=True)\n",
    "            d_loss_f = self.loss_d(y_fake, y_pred_fake)\n",
    "\n",
    "        d_gradient_fake = tape.gradient(d_loss_f, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradient_fake, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Huấn luyện Generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.discriminator(generated_images, training=True)\n",
    "            g_loss = self.loss_g(y_real, y_pred)\n",
    "\n",
    "        g_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_gradient, self.generator.trainable_variables))\n",
    "\n",
    "        # Tính tổng loss của Discriminator\n",
    "        d_loss = (d_loss_r + d_loss_f) / 2\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f6a5eb-afa2-48e2-9cef-c880785cb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator =  keras.random.SeedGenerator(42)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7afa8a04-e226-405e-8249-45c4080d0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name):\n",
    "    (X_train, _), (_, _) = cifar10.load_data()\n",
    "    # Chuyển hình ảnh từ (0 -> 255) về ( -1 -> 1) \n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_train = 2*(X_train/255)-1\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "813ce3fe-82ee-4199-b9b3-9eba674e845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_real, y_pred):\n",
    "    # Tránh log(0) bằng cách thêm epsilon\n",
    "    epsilon = 1e-7\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "    \n",
    "    # Công thức binary crossentropy\n",
    "    return -(y_real * tf.math.log(y_pred) + (1 - y_real) * tf.math.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c1b411-0594-4de5-9f91-5897ce408010",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_d = 2e-4\n",
    "lr_g = 2e-4\n",
    "beta_g = 0.5\n",
    "beta_d = 0.5\n",
    "epochs = 20\n",
    "latent_dim = 128\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "optimizer_generator = Adam(learning_rate=lr_g, beta_1=beta_g)\n",
    "optimizer_discriminator = Adam(learning_rate=lr_d, beta_1=beta_d)\n",
    "\n",
    "d_model = build_discriminator_model()\n",
    "g_model = build_generator_model()\n",
    "\n",
    "cbk = GANMonitor(num_img=3, latent_dim=latent_dim)\n",
    "\n",
    "# Get the dcGans model\n",
    "dcgans = DCGANs(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=latent_dim,\n",
    ")\n",
    "\n",
    "# Compile the wgan model\n",
    "dcgans.compile(\n",
    "    optimizer_discriminator=optimizer_discriminator,\n",
    "    optimizer_generator=optimizer_generator,\n",
    "    loss_d=binary_crossentropy,\n",
    "    loss_g=binary_crossentropy,\n",
    ")\n",
    "\n",
    "X_train = get_data(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81151019-1355-40a4-9487-8c7683daa6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdcgans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcbk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[23], line 58\u001b[0m, in \u001b[0;36mDCGANs.train_step\u001b[0;34m(self, batch_image)\u001b[0m\n\u001b[1;32m     55\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_g(y_real, y_pred)\n\u001b[1;32m     57\u001b[0m g_gradient \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(g_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Tính tổng loss của Discriminator\u001b[39;00m\n\u001b[1;32m     61\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m (d_loss_r \u001b[38;5;241m+\u001b[39m d_loss_f) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable."
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "dcgans.fit(X_train, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af98f0-f467-4f5f-9dbc-d38629d05727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
